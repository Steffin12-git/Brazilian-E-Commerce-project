# \# ğŸ›’ Brazilian E-Commerce Project (Olist)

# 

# \### ğŸš€ \*End-to-End Azure Data Engineering Pipeline Using ADF | ADLS Gen2 | Databricks | Synapse | Power BI\*

# 

# ---

# 

# \## ğŸ“– Project Overview

# 

# This project demonstrates a \*\*complete cloud-based data engineering workflow\*\* using the \*\*Brazilian E-Commerce Public Dataset by Olist\*\*.

# It integrates \*\*multiple Azure services\*\* to ingest, transform, enrich, and visualize e-commerce data in a \*\*Medallion Architecture\*\* (Bronze â†’ Silver â†’ Gold).

# 

# Data is ingested from various sources â€” \*\*GitHub, MySQL, MongoDB\*\* â€” and processed through a pipeline built using \*\*Azure Data Factory\*\*, \*\*Azure Databricks\*\*, \*\*Azure Synapse Analytics\*\*, and finally visualized in \*\*Power BI\*\*.

# 

# ---

# 

# \## ğŸ§© Project Architecture

# 

# !\[Project Structure](Structure%20and%20flow/Project%20Structure.png)

# 

# \*\*Architecture Flow\*\*

# 

# 1\. \*\*Data Sources\*\* â†’ GitHub (JSON), SQL DB (MySQL via Files.io), NoSQL (MongoDB via Files.io)

# 2\. \*\*Azure Data Factory\*\* â†’ Extracts and ingests data into ADLS Gen2 (Bronze)

# 3\. \*\*Azure Databricks\*\* â†’ Transforms \& enriches data (Silver)

# 4\. \*\*Azure Synapse Analytics\*\* â†’ Models \& aggregates data (Gold)

# 5\. \*\*Power BI\*\* â†’ Connects to Synapse for visualization and reporting

# 

# ---

# 

# \## ğŸ§  Technologies \& Tools Used

# 

# | Category                     | Tools / Services                              |

# | ---------------------------- | --------------------------------------------- |

# | \*\*Cloud Platform\*\*           | Microsoft Azure                               |

# | \*\*Storage\*\*                  | Azure Data Lake Storage Gen2                  |

# | \*\*Orchestration\*\*            | Azure Data Factory (ADF)                      |

# | \*\*Processing\*\*               | Azure Databricks with Apache Spark            |

# | \*\*Data Warehouse\*\*           | Azure Synapse Analytics (Serverless SQL Pool) |

# | \*\*Visualization\*\*            | Power BI                                      |

# | \*\*Databases\*\*                | MySQL (Filess.io)  â€¢  MongoDB (Filess.io)     |

# | \*\*Version Control / Source\*\* | GitHub (HTTP JSON metadata + datasets)        |

# 

# ---

# 

# \## ğŸ—‚ Dataset Description

# 

# Dataset: \*\*\[Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)\*\*

# 

# | File                                    | Description                                 |

# | --------------------------------------- | ------------------------------------------- |

# | `olist\_customers\_dataset.csv`           | Customer details                            |

# | `olist\_geolocation\_dataset.csv`         | Geographical mapping                        |

# | `olist\_order\_items\_dataset.csv`         | Products in each order                      |

# | `olist\_order\_payments\_dataset.csv`      | Payment methods and values                  |

# | `olist\_order\_reviews\_dataset.csv`       | Customer reviews and ratings                |

# | `olist\_orders\_dataset.csv`              | Main order information                      |

# | `olist\_products\_dataset.csv`            | Product metadata                            |

# | `olist\_sellers\_dataset.csv`             | Seller details                              |

# | `product\_category\_name\_translation.csv` | Category translations (loaded from MongoDB) |

# 

# ---

# 

# \## â˜ï¸ Azure Setup \& Account Structure

# 

# !\[Azure Account Classification](Structure%20and%20flow/Azure%20account%20classifiation.png)

# 

# All resources were organized under a single \*\*Resource Group\*\* within an Azure subscription using a structured hierarchy:

# 

# \* \*\*Subscription Type:\*\* Azure Free Trial (upgraded to Pay-As-You-Go with Spending Cap)

# \* \*\*Resources Created:\*\*

# 

# &nbsp; \* Azure Data Factory

# &nbsp; \* Azure Data Lake Storage Gen2

# &nbsp; \* Azure Databricks (Workspace + Compute)

# &nbsp; \* Azure Synapse Analytics (Workspace + Serverless SQL Pool)

# &nbsp; \* Power BI Service connection

# 

# ---

# 

# \## ğŸ§± Medallion Architecture

# 

# !\[Medallion Architecture](Structure%20and%20flow/medallion%20architecture.png)

# 

# | Layer      | Purpose                                          | Storage Format  |

# | ---------- | ------------------------------------------------ | --------------- |

# | \*\*Bronze\*\* | Raw data ingestion from ADF                      | CSV             |

# | \*\*Silver\*\* | Cleaned and transformed data from Databricks     | Parquet         |

# | \*\*Gold\*\*   | Aggregated and business-ready tables via Synapse | Parquet / Views |

# 

# ---

# 

# \## ğŸ” Data Pipeline Flow

# 

# \### 1ï¸âƒ£ Azure Data Factory â€“ Data Ingestion

# 

# \* \*\*Linked Services\*\*

# 

# &nbsp; \* GitHub (JSON containing file URLs)

# &nbsp; \* MySQL (Filess.io)

# &nbsp; \* ADLS Gen2 (for storage output)

# 

# \* \*\*Workflow Pipeline\*\*

# 

# &nbsp; \* Lookup â†’ reads JSON metadata from GitHub

# &nbsp; \* ForEach Activity â†’ iterates over file list

# &nbsp; \* Copy Data â†’ dynamically copies each CSV to ADLS Gen2 Bronze folder

# &nbsp; \* Separate Copy Data activity for MySQL data

# 

# ğŸ—ƒ \*\*Output:\*\* All raw files land in `/bronze` container.

# 

# ---

# 

# \### 2ï¸âƒ£ Azure Databricks â€“ Data Transformation \& Enrichment

# 

# \* Connected Databricks to ADLS using Unity Catalog and Managed Identity.

# \* Read CSV files from Bronze â†’ performed data cleaning and joins using PySpark.

# \* Installed and used `pymongo` to connect to MongoDB and load the translation dataset.

# \* Combined all datasets into a final DataFrame using Spark joins on `order\_id`, `customer\_id`, `product\_id`, and `seller\_id`.

# \* Wrote cleaned data to Silver layer in Parquet format.

# 

# ğŸª¶ \*\*Output:\*\* `/silver` container with clean and joined datasets.

# 

# ---

# 

# \### 3ï¸âƒ£ Azure Synapse Analytics â€“ Data Modeling \& Aggregation

# 

# \* Created a Serverless SQL Database.

# \* Configured \*\*External Data Source\*\*, \*\*File Format\*\*, and \*\*Database Scoped Credential\*\* (using Managed Identity).

# \* Queried data from ADLS Silver and created \*\*views\*\* and \*\*aggregated tables\*\*.

# \* Saved final business data into the Gold folder.

# 

# ğŸª™ \*\*Output:\*\* `/gold` container ready for reporting.

# 

# ---

# 

# \### 4ï¸âƒ£ Power BI â€“ Visualization \& Insights

# 

# \* Connected Power BI to Synapse using \*\*Serverless SQL Endpoint\*\*.

# \* Loaded data from Gold views for dashboards and KPIs.

# \* Visualized sales performance, delivery patterns, payment trends, and customer satisfaction.

# 

# ğŸ§© \*\*Visualization Folder:\*\* `/visulisation`

# 

# ---

# 

# \## ğŸ”— Dataset Schema Model

# 

# !\[Dataset Schema Model](Structure%20and%20flow/Dataset%20schema%20model.png)

# 

# This ER diagram illustrates how datasets are joined on `order\_id`, `customer\_id`, `seller\_id`, and `product\_id`.

# 

# ---

# 

# \## ğŸ“š Folder Structure

# 

# ```

# Brazilian-E-Commerce-project/

# â”‚

# â”œâ”€â”€ Azure input file/                 â†’ JSON metadata and scripts

# â”œâ”€â”€ notebook/                         â†’ Databricks notebooks (Spark, PyMongo)

# â”œâ”€â”€ Raw dataset/                      â†’ Original Kaggle CSV files

# â”œâ”€â”€ Structure and flow/               â†’ Architecture and pipeline images

# â”‚     â”œâ”€â”€ Azure account classifiation.png

# â”‚     â”œâ”€â”€ Azure data factory.png

# â”‚     â”œâ”€â”€ Dataset schema model.png

# â”‚     â”œâ”€â”€ medallion architecture.png

# â”‚     â””â”€â”€ Project Structure.png

# â”œâ”€â”€ visulisation/                     â†’ Power BI dashboards and exports

# â””â”€â”€ README.md                         â†’ Project documentation

# ```

# 

# ---

# 

# \## ğŸ§® Key Learnings

# 

# \* Implementing \*\*Medallion Architecture\*\* with ADLS Gen2

# \* Dynamic pipeline creation in ADF using parameters and ForEach

# \* Managed Identity authentication between Azure services

# \* Data transformation in Databricks with PySpark and MongoDB integration

# \* Building a Serverless SQL Data Warehouse in Synapse

# \* Connecting Power BI to Synapse for live analytics

# 

# ---

# 

# \## ğŸš€ Future Enhancements

# 

# \* Automate pipeline trigger with event-based scheduling

# \* Add data-quality checks in ADF and Databricks

# \* Use Azure Monitor for pipeline logging and alerts

# \* Extend visualizations to Azure Fabric or Tableau

# \* Implement ML models in Databricks for sales prediction

# 

# ---

# 

# \## ğŸ™Œ Acknowledgment

# 

# Dataset credit: \[Olist â€“ Brazilian E-Commerce Public Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)

# 

# Project executed and documented by \*\*Steffin Thomas\*\*

# 

# ---

